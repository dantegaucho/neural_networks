{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9fba9c",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "**Convolutional Neural Network (CNN)** is a type of `deep` learning model designed to process data with a grid-like structure, such as images, by using layers that automatically and adaptively learn spatial hierarchies of features. It consists of convolutional layers that apply filters to extract features, pooling layers that reduce spatial dimensions, and fully connected layers for classification. CNNs are widely used in image recognition, object detection, and computer vision tasks due to their efficiency and accuracy.\n",
    "\n",
    "\n",
    "Our task is to build a CNN model capable of correctly classifying whether an image is of the four labels:\n",
    "- `tom`- only contains tom\n",
    "- `jerry`-only contains jerry\n",
    "- `tom_jerry_1` contains both tom and jerry\n",
    "- `tom_jerry_0` contains none of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "##keras models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory\n",
    "base_dir = 'tj'\n",
    "\n",
    "# Check subfolders (should be: tom, jerry, tom_jerry_1, tom_jerry_0)\n",
    "print(\"Subfolders in the dataset directory:\")\n",
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading ground_truth CSV\n",
    "ground_truth_df = pd.read_csv('./csv_data/ground_truth.csv')\n",
    "print(\"\\nGround truth sample:\")\n",
    "ground_truth_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc53d1",
   "metadata": {},
   "source": [
    "Before feeding images into a neural network, we need to know:\n",
    "\n",
    "- What size they are (height × width × channels)\n",
    "\n",
    "- Whether they're consistent in shape\n",
    "\n",
    "- Whether they need resizing\n",
    "\n",
    "CNNs require fixed-size inputs, so this step helps us decide on a common input shape (e.g., **64×64** or **128×128**). We’ll do this randomly by sampling a few images from different folders and inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "folders = ['tom', 'jerry', 'tom_jerry_1', 'tom_jerry_0']\n",
    "\n",
    "#dictionary to hold our samples\n",
    "samples = {}\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    if files:\n",
    "        image = random.choice(files)\n",
    "        img_path = os.path.join(folder_path, image)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        samples[folder] = (img, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets display the image shapes\n",
    "for label, (img, path) in samples.items():\n",
    "    #lin to return the image size\n",
    "    print(f'{label.upper()} image shape: {img.size} - {os.path.basename(path)}')\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Category: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a99335",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Resizing the images\n",
    "Before we move to modelling, we need to preprocess and adjust our images. The most common steps are `resizing` and `flattening`.\n",
    "\n",
    "**Resizing** maintains the sructure of the image but standardizes its size for efficient processing.\n",
    "\n",
    "**Flattening** converts a multi-dimensional array/image into a vector(1D). This helps us in changing a 3D tensor into a 1D tensor for compatibility with dense layers in Neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll use imagedatagenerator to resize \n",
    "size = (64, 64)\n",
    "batch_size = 40 #the number of images to be processed at a time\n",
    "\n",
    "#normalizing the data(think of this as similar step to using StandardScaler)\n",
    "normalize = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "\n",
    "#create training set and validation set\n",
    "train_set = normalize.flow_from_directory(\n",
    "    base_dir, \n",
    "    target_size = size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset='training',\n",
    "    shuffle = True\n",
    "    # color_mode =  'grayscale' #uncomment this line for faster runtime\n",
    ")\n",
    "\n",
    "#validation set \n",
    "validation_set = normalize.flow_from_directory(\n",
    "    base_dir, \n",
    "    target_size = size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset='validation',\n",
    "    shuffle = True\n",
    "    # color_mode =  'grayscale' #uncomment this line for faster runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8cb52",
   "metadata": {},
   "source": [
    "- The `rescale=1.255` is to normalize the pixel values, which were initially RGB(0, 255) to (0, 1).\n",
    "\n",
    "- `flow_from_directory` method from ImageDataGenerator has a special requirement that each of the different classes/labels we are modelling for be in its own subfolder.\n",
    "\n",
    "Now we can move into building our Convolutional Neural Network and flatten the image before passing it into our dense layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##designing our CNN and dense layers\n",
    "model = Sequential()\n",
    "\n",
    "#CNN layer 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "##CNN layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "##flattening before pushing to dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "\"\"\" \n",
    "Design three hidden layers\n",
    "First one with 128 neurons\n",
    "Second one with 64 neurons\n",
    "Third one with 32 neurons\n",
    "\n",
    "Use Dropout technique on the first two with your desired percentage\n",
    "\n",
    "Also include the output layer, choose the correct number of neurons and activation function\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#write your code here\n",
    "\n",
    "model.summary() #this line give you a table-like representation of your design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339dd82",
   "metadata": {},
   "source": [
    "We'll now train our CNN using the training and validation datasets.\n",
    "\n",
    "\n",
    "`PS:` The CNN model extracts different features from the images then our dense layer is used to interpret them and classify the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "during training make sure to pick a small epoch to reduce run-time\n",
    "replace ... with a valid number\n",
    "\"\"\"\n",
    "model.fit(\n",
    "    train_set, \n",
    "    epochs=...,\n",
    "    validation_data = validation_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3533344",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "Lets check how the model performs on the validation set.\n",
    "\n",
    "Here are tables to help you:\n",
    "| Validation Loss | Notes                            |\n",
    "| --------------- | -------------------------------- |\n",
    "| > 1.0           | Model struggling or too simple   |\n",
    "| 0.8 – 1.0       | May still be improving           |\n",
    "| 0.5 – 0.8       | Acceptable, improving            |\n",
    "| 0.2 – 0.5       | Good model performance           |\n",
    "| < 0.2           | Excellent, but check for overfit |\n",
    "\n",
    "And an accuracy table\n",
    "\n",
    "| Accuracy Range | Interpretation                                  |\n",
    "| -------------- | ----------------------------------------------- |\n",
    "| < 60%          | Likely underfitting or data issues              |\n",
    "| 60–75%         | Learning, but room for model/data improvement   |\n",
    "| 75–85%         | Good starting point, acceptable for class demos |\n",
    "| 85–95%         | Strong, usable for screen time analysis         |\n",
    "| > 95%          | Excellent, but check for overfitting            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764caf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation data\n",
    "val_loss, val_accuracy = model.evaluate(validation_set)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.2f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5ad53",
   "metadata": {},
   "source": [
    "###  Prediction \n",
    "Now we need to create a helper function to utilize our model in prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\"\"\"\n",
    "fill in the logic of the function:\n",
    "1. load and preprocess the image\n",
    "2. use the model to predict\n",
    "3. Display the image and the prediction\n",
    "\"\"\"\n",
    "# Mapping from class index to label\n",
    "class_labels = list(train_set.class_indices.keys())\n",
    "\n",
    "def predict_and_render(image_path):\n",
    "\n",
    "    #write your code here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Testing your function on a random image\n",
    "\"\"\"\n",
    "\n",
    "#pick an image path manually\n",
    "sample_image_path = os.path.join(base_dir, 'tom_jerry_1', random.choice(os.listdir(os.path.join(base_dir, 'tom_jerry_1'))))\n",
    "\n",
    "#predict\n",
    "predict_and_render(sample_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
